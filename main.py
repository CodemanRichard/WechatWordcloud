# 微信数据爬取：https://memotrace.cn/
# 字体下载：https://github.com/adobe-fonts

import pandas as pd
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import re
import numpy as np
import PIL.Image as image

def contains_chinese(text):
    pattern = re.compile(r'[\u4e00-\u9fa5]')
    match = pattern.search(str(text))
    return bool(match)

mask = np.array(image.open('mask3.jpg'))
file_path = 'data.csv'
column_name = 'StrContent'
stop_words = {"我", "的", "了", "你", "是", "就是", "也", "在", "他", "都", "就", "吗",
              "吧", "和", "人", "不", "有", "看", "好", "说", "去", "现在", "确实", "感觉", "没有", "那",
              "什么", "这个", "不是", "还是", "还", "这", "真的", "觉得", "没", "啊", "给", "很", "一个",
              "想", "但", "跟", "其实", "怎么", "revokemsg", "可以", "然后", "被", "要", "所以", "但是", "有点",
              "呢", "应该", "能", "不过", "因为", "那个", "那么", "只有", "个", "得", "一直", "主要", "只是", "除了",
              "而且", "像", "会", "又", "太", "特别", "里", "行", "等", "把", "很多", "虽然", "更", "以后", "当时",
              "来", "对", "着", "那种", "不能", "还有", "不会", "之前", "一种", "只能", "已经", "一般", "不好",
              "一条", "消息", "比", "可能", "直接", "这种", "过", "以前", "时候", "不了", "这样", "让", "这么",
              "好像", "多", "如果", "真", "挺", "才", "上", "几个", "到", "谁", "做", "用", "从", "哦",
              "原来", "小", "估计", "最", "最后", "叫", "中", "反正", "全是", "后", "属于", "比较", "其他", "不如",
              "找", "只", "当", "下", "一些", "为什么", "一点", "一次", "出来", "到底", "非常", "是不是", "本来",
              "不要", "完", "点", "群", "别", "带", "男", "出", "之后", "还好", "拿", "不想", "不行", "一样", "再",
              "一下", "有人", "的话", "与", "要是", "将", "或者", "多少", "而", "以为", "咋", "一", "甚至",
              "当然", "大", "走", "肯定", "后来", "我要", "真是", "起来", "最近", "这些", "算", "算了", "哪个",
              "开始", "完全", "基本", "不用", "那些", "问", "有没有", "加", "不敢", "倒", "为了", "变成", "所有",
              "快", "老", "正常", "东西", "妈", "为", "穿", "哭", "嗯", "讲", "里面", "这是", "没事", "放", "关系",
              "地方", "差不多", "不够", "前", "发", "最好", "并", "开", "哪", "怕", "结果", "一堆", "至少",
              "任何", "突然", "需要", "号", "认识", "不到", "一张", "越", "后面", "好多", "没人", "话", "不错",
              "继续", "时", "拍", "每个", "买", "一定", "适合", "事", "学", "之", "几天", "她", "成为", "天天", "记得",
              "只要", "看到", "准备", "事情", "上次", "加入", "年", "少", "见", "每次", "每天", "有个", "别人", "拉",
              "这边", "两个", "嗯", "忘", "它", "明天", "昨天", "刚", "一天", "目前", "新", "知道", "唉", "喜欢",
              "你们", "我们", "各种", "先", "干", "自己", "今天", "他们", "大家", "发现", "经常", "月", "纯",
              "是因为", "分", "以", "本人", "指", "情况", "不然", "之一", "差", "看过", "第一次", "找到", "帮", "想到",
              "来说", "请", "个人", "可", "我来", "别的", "高", "连", "天", "建议", "靠", "有些", "回",
              "推", "马上", "根本", "不少", "地", "居然", "么", "哥", "这里", "几乎", "唯一", "哪里"}

df = pd.read_csv(file_path)
column_data = df[column_name].tolist()
tmp_data = []
for i in column_data:
    if contains_chinese(i):
        tmp_data.append(str(i))
column_data = tmp_data

text = ' '.join(column_data)
words = jieba.lcut(text)
word_string = ' '.join(words)

wordcloud = WordCloud(font_path='fangsong.ttf', mask=mask ,stopwords=stop_words, width=800, height=400, background_color='white').generate(word_string)

"""plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')  # 隐藏坐标轴
plt.show()"""

# 保存词云图像
wordcloud.to_file('chat_wordcloud.png')